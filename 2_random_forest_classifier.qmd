---
title: "Random forest classifier"
subtitle: "Series 2.2.1 - more on imbalanced dataset"
author: Jennifer HY Lin
date: '2023-12-18'
draft: true
categories: 
    - Machine learning projects
    - Tree models
    - Pandas
    - Scikit-learn
    - ChEMBL database
    - Python
jupyter: python3
format: html
bibliography: references.bib
---

##### **Brief introduction**

This post was an addition towards the last post on random forest (RF), machine learning (ML) series 2.2, and was mainly inspired by this paper (cite Esposito et al. on ghostml) from [rinikerlab](https://github.com/rinikerlab). When I started reading the paper, I felt that I should complete the random forest series by adding a random forest classifier model since last post only used a regressor. Another reason was that imbalanced datasets were a common problem in drug discovery projects, and as part of my steep learning curve, I should do something about it. I also decided not to go over too much on the origins of imbalanced datasets in drug discovery as this paper has covered it quite thoroughly. I was also aiming to make this post shorter than the last one (however, every time I sat down writing a post thinking that I should make it shorter, it always turned out to be longer than expected...).

<br>

##### **The plan**

*Introducing new packages - chembl_downloader, random_forest.py & GHOST paper*

<br>

##### **Data retrieval using chembl_downloader**

Introducing chembl_downloader package to get new dataset 
    - data source thoroughness (ChEMBL version, reproducible data source workflow)
    - AChE as target

chembl_downloader reference notebooks:
- https://github.com/cthoyt/chembl-downloader/blob/main/notebooks/drug-indications.ipynb (main reference)
- https://github.com/PatWalters/practical_cheminformatics_tutorials/blob/1f7c61f83eec81081ef2605ac70440bf1940d914/misc/working_with_ChEMBL_drug_data.ipynb#L80 (full download of a specific version of ChEMBL)

```{python}
import pandas as pd
import chembl_downloader
from chembl_downloader import latest, queries, query
import datamol as dm
from rdkit.Chem import Descriptors
from sklearn.ensemble import RandomForestClassifier
```

```{python}
# Show the latest version of ChEMBL used
latest_version = latest()
print(f"The latest ChEMBL version is: {latest_version}")
```

```{python}
# Query chembl_downloader to show SQL required to extract ChEMBL data for a specific protein target
# e.g. target_chembl_id for AChE: CHEMBL220
queries.markdown(queries.get_target_sql(target_id="CHEMBL220", target_type="SINGLE PROTEIN"))
```

```{python}
# Following data download works (4.41GB for SQL query below, may take several min)

# Added MOLECULE_DICTIONARY.max_phase into sql to show max phases for compounds targeting AChE

sql = """
SELECT
    ASSAYS.chembl_id              AS assay_chembl_id,
    TARGET_DICTIONARY.target_type,
    TARGET_DICTIONARY.tax_id,
    TARGET_DICTIONARY.chembl_id,
    COMPOUND_STRUCTURES.canonical_smiles,
    MOLECULE_DICTIONARY.chembl_id AS molecule_chembl_id,
    MOLECULE_DICTIONARY.max_phase,
    ACTIVITIES.standard_type,
    ACTIVITIES.pchembl_value
FROM TARGET_DICTIONARY
     JOIN ASSAYS ON TARGET_DICTIONARY.tid == ASSAYS.tid
     JOIN ACTIVITIES ON ASSAYS.assay_id == ACTIVITIES.assay_id
     JOIN MOLECULE_DICTIONARY ON MOLECULE_DICTIONARY.molregno == ACTIVITIES.molregno
     JOIN COMPOUND_STRUCTURES ON MOLECULE_DICTIONARY.molregno == COMPOUND_STRUCTURES.molregno
WHERE TARGET_DICTIONARY.chembl_id = 'CHEMBL220'
    AND ACTIVITIES.pchembl_value IS NOT NULL
    AND TARGET_DICTIONARY.target_type = 'SINGLE PROTEIN'
"""

df = chembl_downloader.query(sql)
```

```{python}
df.head()
```

```{python}
# Save df as .csv file
df.to_csv("chembl_d_ache", sep=",", index=False)
```

```{python}
# Load dataset from saved .csv file
df_ache = pd.read_csv("chembl_d_ache")
print(df_ache.shape)
df_ache.head()
```

```{python}
#df.value_counts("chembl_id")
```

<br>

##### **Some data cleaning**

Minor cleaning and preprocessing as focus this time was on dealing with imbalanced datasets in RF classifier.

###### **random_forest.py (work-in-progress):**

The idea was to remove most function code in the post and save all code as a separate script (avoid repeating code from last few posts).

```{python}
## Trial random_forest.py script
from random_forest import preprocess, rdkit_2d_descriptors
```

```{python}
# Running preprocess function
df_ache = df_ache.copy()
df_prep = df_ache.apply(preprocess, axis = 1)
df_prep.head()
```

```{python}
# Running rdkit_2d_descriptors function
df_2d = rdkit_2d_descriptors(df_prep)
```

```{python}
df_2d
```

```{python}
# Merge dataframes df_prep & df_2d via index
df_merge = pd.merge(
    df_prep[["max_phase", "molecule_chembl_id"]],
    df_2d,
    left_index=True,
    right_index=True
)
```

```{python}
print(df_merge.shape)
df_merge.head()
```

Different spreads of max phases as the SQL query used IC50 (whereas last post used Ki). There were more max phase 4 compounds than null compounds.

```{python}
# Find out counts of each max phase
df_merge.value_counts("max_phase")
```

```{python}
# Try searching for the chembl_id of the 10 max phase 4 compounds from last post in df_merge (or at least to contain the common AChE inhibitors e.g. galantamine, donepezil etc.)

# Previously used 10 max phase 4 compounds
list_mp4 = ["CHEMBL95", "CHEMBL1128", "CHEMBL640", "CHEMBL502", "CHEMBL481", "CHEMBL360055", "CHEMBL1025", "CHEMBL659", "CHEMBL1200970", "CHEMBL1677"]

# donepezil & galantamine
# list_mp4 = ["CHEMBL502", "CHEMBL659"]

# Series.isin
# df2.loc[df2['C'].isin(name)]

# Search for the compounds in list_mp4 in df_merge's "molecule_chembl_id" column
df_prev = df_merge.loc[df_merge["molecule_chembl_id"].isin(list_mp4)]
# Many duplicates
```

```{python}
# Some compounds with duplicates
print(df_prev.shape)
df_prev.value_counts("molecule_chembl_id")
```

```{python}
# Dropping duplicated compound chembl ids
df_merge_new = df_merge.drop_duplicates(subset=["molecule_chembl_id"], keep="first")
print(df_merge_new.shape)
df_merge_new.head()
```

```{python}
# Previously used 10 max phase 4 compounds were found in df_merge_new
df_mp4 = df_merge_new.loc[df_merge_new["molecule_chembl_id"].isin(list_mp4)]
```

```{python}
print(df_mp4.shape)
```

```{python}
# Compounds with max phase 0 not shown
df_merge_new.value_counts("max_phase")
```

```{python}
print(df_merge_new.shape)
```

```{python}
df_merge_new.fillna("null")
```

```{python}
# Select all max phase null compounds
df_null = df_merge_new[df_merge_new["max_phase"] == "null"]
```

```{python}
## Aiming to use imbalanced dataset (inactives > actives)

# Use df_mp4 as training set (10 compounds)
# Use df_null as testing set (5256 compounds)


## re-label max phases as binary labels (e.g. max phase null as 0, max phase 4 as 1) 

```

<br>

##### **Model building**

* aim to model and classify the max phase of ChEMBL small molecules (max phase 4 or not)
    - *target*: max_phase
    - *features*: various RDKit 2D descriptors (RDKit2D)

1. re-label max phases as binary labels (e.g. max phase null as 0, max phase 4 as 1) 

2. train RF classifier model as usual (focus is on an imbalanced dataset of actives and inactives) - using similar set of training data as last post but not exactly the same as using chembl_downloader this time to extract data

3. get the prediction probabilities of the RF classifier on testing data & show confusion matrix with classification metrics

4. two approaches from GHOST paper (main idea was optimising and shifting decision threshold)
    - approach 1 based on RDKit blog post (ref. 41)
    - approach 2 led to Generalised threshold shifting (GHOST) procedure - ghostml code
    *using only approach 2 ghostml - as both approaches were shown to be performing similarly in the paper and also approach 1 was already described in a RDKit blog post*

5. shift decision threshold using ghostml, a postprocessing way (note: last post used re-sampling method in a preprocessing way)
    - extract the prediction probabilities from the RF classifier trained model
    - optimise the decision threshold using ghostml via testing various thresholds (in spaces of 0.05 with range of 0.05 to 0.5) - to search for the threshold that has maximised the Cohen's kappa
    - calculate confusion matrix and classification metrics based on the optimised decision threshold