---
title: "Random forest classifier"
subtitle: "Series 2.2.1 - more on imbalanced dataset"
author: Jennifer HY Lin
date: '2024-1-1'
draft: true
categories: 
    - Machine learning projects
    - Tree models
    - Pandas
    - Scikit-learn
    - ChEMBL database
    - Python
jupyter: python3
format: html
bibliography: references.bib
---

##### **Brief introduction**

This post was really just an addition towards the last random forest (RF) post (machine learning (ML) series 2.2). It was mainly inspired by this paper (cite Esposito et al. on ghostml) from [rinikerlab](https://github.com/rinikerlab). Also, it was nice to complete the random forest series by adding a random forest classifier model since last post only used a regressor. I also tried to have another look again on imbalanced datasets which were common in real-life drug discovery projects, and also it was the main reason to use the code from the paper mentioned. While I was working on this post, I've also come across a few other packages that I haven't used before so I thought it might be useful to mention them here too.

**Mention outcome here - the change in Cohen's kappa or improvement in confusion matrix after using ghostml**

<br>

##### **Overview**

* Data source using *chembl_downloader*
* Own little script of random_forest.py (avoid repeating code)
* SMILES checker from *scikit_mol*
* Dealing with imbalanced datasets in RF classifiers by using *ghostml*

<br>

##### **Importing libraries**

```{python}
import pandas as pd
import numpy as np
import chembl_downloader
from chembl_downloader import latest, queries, query
import datamol as dm
from rdkit.Chem import Descriptors
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.model_selection import train_test_split
#from rdkit.Chem import PandasTools
from scikit_mol.utilities import CheckSmilesSanitazion
import ghostml
```

<br>

##### **Data retrieval using chembl_downloader**

Introducing chembl_downloader package to get new dataset 
    - data source thoroughness (ChEMBL version, reproducible data source workflow)
    - AChE as target

chembl_downloader reference notebooks:
- https://github.com/cthoyt/chembl-downloader/blob/main/notebooks/drug-indications.ipynb (main reference)
- https://github.com/PatWalters/practical_cheminformatics_tutorials/blob/1f7c61f83eec81081ef2605ac70440bf1940d914/misc/working_with_ChEMBL_drug_data.ipynb#L80 (full download of a specific version of ChEMBL)

```{python}
# Show the latest version of ChEMBL used
latest_version = latest()
print(f"The latest ChEMBL version is: {latest_version}")
```

```{python}
# Query chembl_downloader to show SQL required to extract ChEMBL data for a specific protein target
# e.g. target_chembl_id for AChE: CHEMBL220
queries.markdown(queries.get_target_sql(target_id="CHEMBL220", target_type="SINGLE PROTEIN"))
```

```{python}
# Following data download works (4.41GB for SQL query below, may take several min)

# Added MOLECULE_DICTIONARY.max_phase into sql to show max phases for compounds targeting AChE

sql = """
SELECT
    ASSAYS.chembl_id              AS assay_chembl_id,
    TARGET_DICTIONARY.target_type,
    TARGET_DICTIONARY.tax_id,
    TARGET_DICTIONARY.chembl_id,
    COMPOUND_STRUCTURES.canonical_smiles,
    MOLECULE_DICTIONARY.chembl_id AS molecule_chembl_id,
    MOLECULE_DICTIONARY.max_phase,
    ACTIVITIES.standard_type,
    ACTIVITIES.pchembl_value
FROM TARGET_DICTIONARY
     JOIN ASSAYS ON TARGET_DICTIONARY.tid == ASSAYS.tid
     JOIN ACTIVITIES ON ASSAYS.assay_id == ACTIVITIES.assay_id
     JOIN MOLECULE_DICTIONARY ON MOLECULE_DICTIONARY.molregno == ACTIVITIES.molregno
     JOIN COMPOUND_STRUCTURES ON MOLECULE_DICTIONARY.molregno == COMPOUND_STRUCTURES.molregno
WHERE TARGET_DICTIONARY.chembl_id = 'CHEMBL220'
    AND ACTIVITIES.pchembl_value IS NOT NULL
    AND TARGET_DICTIONARY.target_type = 'SINGLE PROTEIN'
"""

df = chembl_downloader.query(sql)
```

```{python}
df.head()
```

```{python}
# Save df as .csv file
df.to_csv("chembl_d_ache", sep=",", index=False)
```

```{python}
# Load dataset from saved .csv file
df_ache = pd.read_csv("chembl_d_ache")
print(df_ache.shape)
df_ache.head()
```

```{python}
# Check it was only AChE
#df.value_counts("chembl_id")
```

<br>

##### **Some data cleaning**

Minor cleaning and preprocessing as focus this time was on dealing with imbalanced datasets in RF classifier.

###### **random_forest.py (work-in-progress)**

The idea was to remove most function code in the post and save all code as a separate script (avoid repeating code from last few posts).

```{python}
## Trial random_forest.py script
from random_forest import preprocess, rdkit_2d_descriptors
```

```{python}
## Preprocess/standardise molecules
# Running preprocess function 
df_ache = df_ache.copy()
df_prep = df_ache.apply(preprocess, axis = 1)
df_prep.head()
```

<br>

###### **scikit_mol**

Introducing a new package, scikit_mol, which originated from 2022 RDKit UGM hackathon. The blog post link below elaborated further about the package. I've only used it for the purpose of checking for missing SMILES or errors in SMILES, but it has much more functions than this - potentially very useful for integrating with scikit-learn's pipeline method. Its repository should inform more details.

GitHub Repo: https://github.com/EBjerrum/scikit-mol
Blog post: https://www.cheminformania.com/scikit-mol-easy-embedding-of-rdkit-into-scikit-learn/

```{python}
# Quick simple way to check for missing SMILES
print(f'Dataset contains {df_prep.standard_smiles.isna().sum()} unparsable mols')
```

No unparsable (or missing) molecules.

```{python}
# Checking for invalid SMILES
smileschecker = CheckSmilesSanitazion()

smileschecker.sanitize(list(df_prep.standard_smiles))

# Showing SMILES errors
smileschecker.errors
```

Confirmed that there were no errors in SMILES.

```{python}
## Generate RDKit2D descriptors/fingerprints
# Running rdkit_2d_descriptors function
df_2d = rdkit_2d_descriptors(df_prep)
df_2d
```

```{python}
# Merge dataframes df_prep & df_2d via index
df_merge = pd.merge(
    df_prep[["max_phase", "molecule_chembl_id"]],
    df_2d,
    left_index=True,
    right_index=True
)
```

```{python}
print(df_merge.shape)
df_merge.head()
```

Different spreads of max phases as the SQL query mainly used IC50 (whereas last post was strictly limited to Ki, done via ChEMBL web resource client). Other reason was that in the decision tree series, I attempted data preprocessing at a larger scale (which eliminated some data). So, it appeared that there were more max phase 4 compounds here than last time (Note: null compounds were not shown in the value counts here as it was labelled as "NaN", but it should be the largest portion of max phase in the data).

```{python}
# Find out counts of each max phase
df_merge.value_counts("max_phase")
```

```{python}
# Try searching for the chembl_id of the 10 max phase 4 compounds from last post in df_merge (or at least to contain the common AChE inhibitors e.g. galantamine, donepezil etc.)

# Previously used 10 max phase 4 compounds
list_mp4 = ["CHEMBL95", "CHEMBL1128", "CHEMBL640", "CHEMBL502", "CHEMBL481", "CHEMBL360055", "CHEMBL1025", "CHEMBL659", "CHEMBL1200970", "CHEMBL1677"]

# donepezil & galantamine
# list_mp4 = ["CHEMBL502", "CHEMBL659"]

# using Series.isin
# df2.loc[df2['C'].isin(name)]

# Search for the compounds in list_mp4 within df_merge's "molecule_chembl_id" column
df_prev = df_merge.loc[df_merge["molecule_chembl_id"].isin(list_mp4)]
df_prev
# Many duplicates
```

```{python}
# Some compounds with duplicates
print(df_prev.shape)
df_prev.value_counts("molecule_chembl_id")
```

```{python}
# Dropping duplicated compound chembl ids
df_merge_new = df_merge.drop_duplicates(subset=["molecule_chembl_id"], keep="first")
print(df_merge_new.shape)
df_merge_new.head()
```

```{python}
# Previously used 10 max phase 4 compounds were found in df_merge_new
df_mp4 = df_merge_new.loc[df_merge_new["molecule_chembl_id"].isin(list_mp4)]

print(df_mp4.shape)
```

```{python}
# Compounds with max phase 0 not shown
df_merge_new.value_counts("max_phase")
```

<br>

##### **Model building**

* aim to model and classify the max phase of ChEMBL small molecules (max phase 4 or not)
    - *target*: max_phase
    - *features*: various RDKit 2D descriptors (RDKit2D)

1. re-label max phases as binary labels (e.g. max phase null as 0, max phase 4 as 1) 

```{python}
# Re-label max phase NaN as 0
#df_merge_new = df_merge_new.fillna("null")
df_merge_new = df_merge_new.fillna(0)

df_merge_new
```

---Splitting data into max phase null & max phase 4---

```{python}
# Select all max phase null compounds
df_null = df_merge_new[df_merge_new["max_phase"] == 0]
print(df_null.shape)
df_null.head()
```

```{python}
# The 10 max phase 4 compounds used in last post
df_mp4
```

```{python}
## Aiming to use imbalanced dataset (inactives > actives)

## re-label max phases as binary labels 
# (e.g. max phase null as 0, max phase 4 as 1)

# Using pd.DataFrame.assign to add a new column to re-label max_phase 4 into "1"
df_mp4_lb = df_mp4.assign(max_phase_lb = df_mp4["max_phase"] / 4)

# Using pd.DataFrame.pop() & insert() to shift added column to first column position
first_col = df_mp4_lb.pop("max_phase_lb")
df_mp4_lb.insert(0, "max_phase_lb", first_col)

df_mp4_lb
# df_merge_new
```

```{python}
# If carrying out assign() /4 on column max_phase on df_merge_new
# It divided every max phase values by 4!! -> weird max phase values now
# df_merge_new.value_counts("max_phase_lb")
```

```{python}
# Also create a new column max_phase_lb column for df_null to merge 2 dfs after

df_null_lb = df_null.assign(max_phase_lb = df_null["max_phase"])
first_col_null = df_null_lb.pop("max_phase_lb")
df_null_lb.insert(0, "max_phase_lb", first_col_null)
df_null_lb.head()
```

```{python}
df_mp4_lb.head()
```

The two dataframes should share same column names so that they could be combined together.

```{python}
# Concatenate df_mp4_lb & df_null_lb
df_full = pd.concat([df_null_lb, df_mp4_lb])
df_full
```

2. train RF classifier model as usual (focus is on an imbalanced dataset of actives and inactives) - using same set of training data as last post (on the same 10 compounds)

---Previous data splits into arrays begins---

* Training dataset

```{python}
# Selecting training data via data positions using iloc
# X_train = df_mp4_lb.iloc[:, 3:]
# X_train = X_train.to_numpy()
# X_train

# Defining X - features & y - target
X = df_full.iloc[:, 3:]
y = df_full.iloc[:, 0]
```

```{python}
# Convert both X & y to arrays
X = X.to_numpy()
y = y.to_numpy()
```

```{python}
y
```

```{python}
# Target variable in training data
# y_train = df_mp4_lb[["max_phase_lb"]]
# y_train = y_train.to_numpy()
# Change column-vector y into a 1D array (changing shape) - ndarray.ravel()
# y_train = y_train.ravel()
```

* Testing dataset

```{python}
# print(df_null.shape)
```

```{python}
# Testing data using df_null dataset
# X_test = df_null.iloc[:, 2:]
# X_test = X_test.to_numpy()
# X_test
```

```{python}
# Define y_test
# y_test = df_null.iloc[:,0]
# y_test = y_test.to_numpy()
```

---Previous data splits into arrays ends---

```{python}
# Using train_test_split() this time to split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)
```

* Use df_mp4 as actives (10 compounds)
* Use df_null as inactives (5256 compounds)

* Training RF classifier model

```{python}
# Ref notebook: https://github.com/rinikerlab/GHOST/blob/main/notebooks/example_GHOST.ipynb

# Using RandomForestClassifier() to train model
rfc = RandomForestClassifier(max_depth=3, random_state=1, max_features="sqrt", oob_score=True)
rfc.fit(X_train, y_train)
```

3. get the prediction probabilities on the testing data & show confusion matrix with classification metrics

```{python}
# Extract positive prediction probabilities for the testing set
test_probs = rfc.predict_proba(X_test)[:, 1]
```

A useful web link on area under the ROC curve - https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc

```{python}
# To avoid re-inventing the wheel, the following function code for calculating metrics of the RF model was adapted from Landrum et al., from this notebook: https://github.com/rinikerlab/GHOST/blob/main/notebooks/example_GHOST.ipynb

def calc_metrics(labels_test, test_probs, threshold = 0.5):
    scores = [1 if x>=threshold else 0 for x in test_probs]
    auc = metrics.roc_auc_score(labels_test, test_probs)
    kappa = metrics.cohen_kappa_score(labels_test, scores)
    confusion = metrics.confusion_matrix(labels_test,scores, labels=list(set(labels_test)))
    print('thresh: %.2f, kappa: %.3f, AUC test-set: %.3f'%(threshold, kappa, auc))
    print(confusion)
    print(metrics.classification_report(labels_test,scores))
    return 
```

```{python}
# Problem with y_test - only one label in it (1 only), needs binary labels (0 & 1) 
# needed for roc_auc_score (measures true +ve & false +ve rates)

calc_metrics(y_test, test_probs, threshold = 0.5)

# This was an extreme case - as only 10 actives vs. 5256 inactives
```

4. two approaches from GHOST paper (main idea was optimising and shifting decision threshold)
    - approach 1 based on RDKit blog post (ref. 41)
    - approach 2 led to Generalised threshold shifting (GHOST) procedure - ghostml code
    *using only approach 2 ghostml - as both approaches were shown to be performing similarly in the paper and also approach 1 was already described in a RDKit blog post*

```{python}
# Get the positive prediction probabilities of the training set
train_probs = rfc.predict_proba(X_train)[:, 1]
```

5. shift decision threshold using ghostml, a postprocessing way (note: last post used re-sampling method in a preprocessing way)
    - extract the prediction probabilities from the RF classifier trained model
    - optimise the decision threshold using ghostml via testing various thresholds (in spaces of 0.05 with range of 0.05 to 0.5) - to search for the threshold that has maximised the Cohen's kappa
    - calculate confusion matrix and classification metrics based on the optimised decision threshold

```{python}
# Looking for the most optimal threshold
# Setting up different decision thresholds in space of 0.05
thresholds = np.round(np.arange(0.05,0.55,0.05),2)
thresholds
```

```{python}
# The ghostml source code that worked as how the paper explained - looking for the best threshold with the most optimal Cohen's Kappa
new_threshold = ghostml.optimize_threshold_from_predictions(y_train, train_probs, thresholds, ThOpt_metrics = 'Kappa') 
```

```{python}
#type(threshold1)
new_threshold
```

```{python}
# Using calc_metrics function again on the newly-found/shifted decision threshold
# It showed an improved classification outcome through the confusion matrix
calc_metrics(y_train, train_probs, threshold=new_threshold)
```